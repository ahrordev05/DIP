{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Colab drive mount (optional)\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"Google Drive mounted.\")\nexcept Exception:\n    print(\"Running outside Google Colab; skipping Drive mount.\")\n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdZVYgGf2p2Z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940020876,
     "user_tz": -300,
     "elapsed": 23688,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "4db190a9-5d8f-4735-b345-34208c431692"
   },
   "id": "QdZVYgGf2p2Z",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b82bd103",
   "metadata": {
    "id": "b82bd103"
   },
   "source": [
    "# Digital Image Processing — Lab Notebook (Student Version)\n",
    "\n",
    "This notebook combines the lab materials into a single, ordered workflow.  \n",
    "Run cells top-to-bottom. Wherever you see **TASK**, complete the short exercise.\n",
    "\n",
    "**Topics**\n",
    "1. Bitwise operators & masking  \n",
    "2. Bit-plane slicing  \n",
    "3. Histogram processing  \n",
    "4. Image enhancement  \n",
    "5. Noise generation\n",
    "\n",
    "> **Note:** Use your own image files where needed (e.g., `images/sample.jpg`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2fcae",
   "metadata": {
    "id": "41a2fcae"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell first. It imports the libraries used across the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1722b",
   "metadata": {
    "id": "fad1722b"
   },
   "outputs": [],
   "source": "from pathlib import Path\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n\ndef show(img, title=None, cmap=None):\n    \"\"\"Display helper for both grayscale and color images.\"\"\"\n    plt.figure(figsize=(6, 4))\n    if img.ndim == 2:\n        plt.imshow(img, cmap=cmap or \"gray\")\n    else:\n        plt.imshow(img)\n    if title:\n        plt.title(title)\n    plt.axis(\"off\")\n    plt.show()\n\n\ndef _first_existing(candidates):\n    for p in candidates:\n        path = Path(p)\n        if path.exists():\n            return str(path)\n    return None\n\n\ndef read_gray(candidates, fallback_shape=(256, 256), seed=0):\n    \"\"\"Read grayscale image from candidate paths; fallback to synthetic image.\"\"\"\n    path = _first_existing(candidates)\n    if path is not None:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        if img is not None:\n            print(f\"Loaded grayscale image: {path}\")\n            return img\n\n    print(\"Using synthetic grayscale fallback image.\")\n    rng = np.random.default_rng(seed)\n    return (rng.random(fallback_shape) * 255).astype(np.uint8)\n\n\ndef read_color(candidates, fallback_shape=(256, 256), seed=0):\n    \"\"\"Read color image from candidate paths; fallback to synthetic color image.\"\"\"\n    path = _first_existing(candidates)\n    if path is not None:\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        if img is not None:\n            print(f\"Loaded color image: {path}\")\n            return img\n\n    print(\"Using synthetic color fallback image.\")\n    h, w = fallback_shape\n    rng = np.random.default_rng(seed)\n    grad = np.tile(np.linspace(0, 255, w, dtype=np.uint8), (h, 1))\n    ch3 = rng.integers(0, 256, size=(h, w), dtype=np.uint8)\n    return np.dstack((grad, np.flipud(grad), ch3))\n"
  },
  {
   "cell_type": "markdown",
   "id": "cf600174",
   "metadata": {
    "id": "cf600174"
   },
   "source": [
    "---\n",
    "\n",
    "# 1) Bitwise Operators & Masking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bf1c9",
   "metadata": {
    "id": "129bf1c9"
   },
   "source": [
    "## Objectives\n",
    "- Understand AND / OR / XOR / NOT on binary images\n",
    "- Create simple masks and apply them to regions of interest (ROI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832262d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "4832262d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940089762,
     "user_tz": -300,
     "elapsed": 939,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "7dfa812b-254e-458b-f0e1-6dd8f1e425e1"
   },
   "outputs": [],
   "source": "image_data = read_gray(\n    [\n        \"/content/drive/MyDrive/DIP/ai-image.jpg\",\n        \"ai-image.jpg\",\n        \"../lab1/img.png\",\n        \"../lab1/img_1.png\",\n    ],\n    fallback_shape=(420, 700),\n    seed=1,\n)\n\nshow(image_data, \"Grayscale Image\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234b549",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7234b549",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940094677,
     "user_tz": -300,
     "elapsed": 9,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "586b58cd-055a-4345-cc59-f2137c916dd3"
   },
   "outputs": [],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccf291",
   "metadata": {
    "id": "dfccf291"
   },
   "source": [
    "## Bitwise operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf63524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "3cf63524",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940122824,
     "user_tz": -300,
     "elapsed": 834,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "c7218805-f4fb-4ce5-ef2c-23fab9f80992"
   },
   "outputs": [],
   "source": [
    "# initialize masks\n",
    "mask1 = np.zeros(image_data.shape[:2], np.uint8)\n",
    "mask2 = np.zeros(image_data.shape[:2], np.uint8)\n",
    "\n",
    "# draw rectangles\n",
    "cv2.rectangle(mask1, (90, 120), (380, 380), 255, -1)\n",
    "cv2.rectangle(mask2, (350, 10), (635, 380), 255, -1)\n",
    "\n",
    "# display using matplotlib\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask1, cmap='gray')\n",
    "plt.title(\"Mask 1\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask2, cmap='gray')\n",
    "plt.title(\"Mask 2\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa63c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "0aa63c4d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940187323,
     "user_tz": -300,
     "elapsed": 417,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "b362ec75-5961-496f-9d75-937e088a5926"
   },
   "outputs": [],
   "source": [
    "# Shows only where they intersect\n",
    "And = cv2.bitwise_and(mask1, mask2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(And, cmap='gray')\n",
    "plt.title(\"AND (Intersection)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d807d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "db0d807d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940206551,
     "user_tz": -300,
     "elapsed": 635,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "d9897fb4-9431-4ce3-a431-a65d988b4cee"
   },
   "outputs": [],
   "source": [
    "# Shows where either mask1 or mask2 is white\n",
    "bitwiseOr = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(bitwiseOr, cmap='gray')\n",
    "plt.title(\"OR (Union)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcad55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "28dcad55",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940222389,
     "user_tz": -300,
     "elapsed": 447,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "abd9c6c9-90d3-4a89-e94b-96243eecc913"
   },
   "outputs": [],
   "source": [
    "# Shows where either exists by itself (non-overlapping regions)\n",
    "bitwiseXor = cv2.bitwise_xor(mask1, mask2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(bitwiseXor, cmap='gray')\n",
    "plt.title(\"XOR (Exclusive OR)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5114b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "c7f5114b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940239218,
     "user_tz": -300,
     "elapsed": 417,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "16872635-ce8f-43e1-fec0-83b7d2d26e55"
   },
   "outputs": [],
   "source": [
    "# Shows everything that isn't part of mask1\n",
    "bitwiseNot_sq = cv2.bitwise_not(mask1)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(bitwiseNot_sq, cmap='gray')\n",
    "plt.title(\"NOT (Mask 1)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e949b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "32e949b2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940253869,
     "user_tz": -300,
     "elapsed": 413,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "4bf4743b-2577-48ae-bf72-3c788af1ea45"
   },
   "outputs": [],
   "source": [
    "# Invert mask2\n",
    "bitwiseNot_ell = cv2.bitwise_not(mask2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(bitwiseNot_ell, cmap='gray')\n",
    "plt.title(\"NOT (Mask 2)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6fd12",
   "metadata": {
    "id": "dab6fd12"
   },
   "source": [
    "So far we applied masks together with one another. But we can use the same operators to now apply the masks to the image itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41a1a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "6a41a1a0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940272133,
     "user_tz": -300,
     "elapsed": 247,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "dbcb13c2-9d1b-4e14-aef2-2a33f7645083"
   },
   "outputs": [],
   "source": "# Apply mask1 to the original image\nmasked1 = cv2.bitwise_and(image_data, image_data, mask=mask1)\nshow(masked1, \"Only Show Masked Region (Mask 1)\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868bafbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "868bafbd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940288233,
     "user_tz": -300,
     "elapsed": 217,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "359939f6-7f6f-46d7-b0f8-6ea2704553d1"
   },
   "outputs": [],
   "source": "# Apply mask2 to the original image\nmasked2 = cv2.bitwise_and(image_data, image_data, mask=mask2)\nshow(masked2, \"Only Show Masked Region (Mask 2)\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fd43a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "596fd43a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940303183,
     "user_tz": -300,
     "elapsed": 203,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "df0f3338-2757-4cf5-a14f-8dba78950bb1"
   },
   "outputs": [],
   "source": "# Apply intersection mask (AND) to the original image\nmasked_and = cv2.bitwise_and(image_data, image_data, mask=And)\nshow(masked_and, \"Intersection of Mask 1 & Mask 2\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b5feb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "8f8b5feb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940320802,
     "user_tz": -300,
     "elapsed": 349,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "8e4516e2-159f-4112-b10b-191d260ee325"
   },
   "outputs": [],
   "source": "# Apply OR mask to the original image\nmasked_or = cv2.bitwise_and(image_data, image_data, mask=bitwiseOr)\nshow(masked_or, \"Union of Both Masks (Two Regions)\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "f42ba2fb",
   "metadata": {
    "id": "f42ba2fb"
   },
   "source": [
    "### TASK 1 — Create a circular mask (easy)\n",
    "\n",
    "1. Load or create a grayscale image (e.g., a synthetic gradient).\n",
    "2. Create a **circular** binary mask.\n",
    "3. Use `cv2.bitwise_and` to keep only pixels inside the circle.\n",
    "\n",
    "Write your solution in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33583025",
   "metadata": {
    "id": "33583025"
   },
   "outputs": [],
   "source": "# TODO completed: circular mask example\nimg = np.tile(np.linspace(0, 255, 400, dtype=np.uint8), (300, 1))\n\nh, w = img.shape\nmask = np.zeros((h, w), dtype=np.uint8)\n\ncx, cy = w // 2, h // 2\nr = min(h, w) // 4\ncv2.circle(mask, (cx, cy), r, 255, -1)\n\nmasked = cv2.bitwise_and(img, img, mask=mask)\n\nshow(img, \"Original\", cmap=\"gray\")\nshow(mask, \"Circular Mask\", cmap=\"gray\")\nshow(masked, \"Masked result\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "84e4b474",
   "metadata": {
    "id": "84e4b474"
   },
   "source": [
    "---\n",
    "\n",
    "# 2) Bit-Plane Slicing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9984a84",
   "metadata": {
    "id": "b9984a84"
   },
   "source": [
    "## Objectives\n",
    "- Extract and visualize bit-planes (0–7) of an 8-bit grayscale image\n",
    "- Observe how higher-order planes carry most structural information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75214b0",
   "metadata": {
    "id": "a75214b0"
   },
   "source": [
    "# Bit-plane Slicing\n",
    "\n",
    "**Image** is basically combination of individual pixel (dots) information. When we write that image is of 620 X 480 size, it means that image has 620 pixel in horizontal direction and 480 pixel in vertical direction. So, altogether there is 620 X 480 pixels and each pixels contains some information about image.\n",
    "\n",
    "**Grayscale** image are basically those image which we say black and white image. Each pixel of grayscale image has a value lies in between **0 – 255** which decides at which position, the image will be black and at which position, it will be white.\n",
    "\n",
    "If pixel value is **0**, it means that pixel color will be fully black and if pixel value is **255**, then that pixel will be fully white and pixel having intermediate value will be having shades of black and white.\n",
    "\n",
    "We are given a Grayscale Image. Since pixel value of grayscale image lies between **0 -255**, so its information is contained using **8 bit**.\n",
    "\n",
    "So, we can divide those image into **8 planes** (8 Binary Image or **8 B&W image**). Binary image are those images whose pixel value can be either 0 or 1.\n",
    "\n",
    "So, Our task is to extract each bit planes of original image to make 8 binary image\n",
    "\n",
    "### for example\n",
    "pixel of grayscale image has value **212**. So, its binary value will be **11010100**. So, its 1st bit is 0, 2nd is 0, 3rd is 1, 4rth is 0, 5th is 1, 6th is 0, 7th is 1, 8th is 1. In this manner, we will take these 8 bit of all pixel and will draw 8 binary image. We have to do this to all the pixels and generate new images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8e666",
   "metadata": {
    "id": "8bd8e666"
   },
   "source": [
    "A gray scale image has pixels with values between 0 and 255 and we need 8 bits to\n",
    "store these numbers, in this method we extract these 8 bits and each pixel can\n",
    "represent 8 binary numbers (0,1) and therefore We can have 8 matrices (8 black and\n",
    "white images) for a gray scale image, which are the elements or planes that make up\n",
    "the original image.\n",
    "\n",
    "When we move from low value bit planes (Bit0) to high value planes (Bit7), we get\n",
    "more information in them.\n",
    "So we can delete low-value planes (such Bit0) and still have the original image\n",
    "information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68917ef7",
   "metadata": {
    "id": "68917ef7"
   },
   "source": [
    "### TASK 2 — Reconstruct an image from selected bit-planes\n",
    "\n",
    "1. Extract bit-planes `b7`, `b6`, `b5` (the three most significant planes).\n",
    "2. Reconstruct an approximation of the original image using only these planes.\n",
    "3. Compare reconstruction vs original visually.\n",
    "\n",
    "Implement below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486895b",
   "metadata": {
    "id": "0486895b"
   },
   "outputs": [],
   "source": [
    "# TODO: load an image (grayscale)\n",
    "# img = cv2.imread(\"images/sample.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Demo fallback (remove if using your own image):\n",
    "img = (np.random.rand(256,256)*255).astype(np.uint8)\n",
    "\n",
    "# Extract planes (planes[i] is bit i)\n",
    "planes = [(img >> i) & 1 for i in range(8)]\n",
    "\n",
    "# Reconstruct using planes 7,6,5\n",
    "recon = np.zeros_like(img, dtype=np.uint8)\n",
    "for i in [7,6,5]:\n",
    "    recon = recon + (planes[i].astype(np.uint8) << i)\n",
    "\n",
    "show(img, \"Original (or demo)\", cmap=\"gray\")\n",
    "show(recon, \"Reconstruction from b7,b6,b5\", cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527a691",
   "metadata": {
    "id": "8527a691"
   },
   "source": [
    "---\n",
    "\n",
    "# 3) Histogram Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c9852",
   "metadata": {
    "id": "a01c9852"
   },
   "source": [
    "## Objectives\n",
    "- Compute and plot image histograms\n",
    "- Perform histogram equalization and contrast stretching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c751ce",
   "metadata": {
    "id": "a3c751ce"
   },
   "source": [
    "# Image Histogram Processing\n",
    "\n",
    "![histogram of an image](dataset/imgs/histeq.png)\n",
    "\n",
    "In this section you will see how to calculate and plot the histogram and cumulative histogram of an image using OpenCV in python.\n",
    "\n",
    "You can find more information in OpenCV documentation and tutorials.\n",
    "[here](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2795d5",
   "metadata": {
    "id": "fc2795d5"
   },
   "source": [
    "Install and Import required packages necessary for image processing.\n",
    "\n",
    "install required packages with python packages manager (PIP)\n",
    "```cmd\n",
    "pip install opencv-python\n",
    "pip install matplotlib\n",
    "pip install numpy\n",
    "pip install scikit-image\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68980dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "68980dbd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940950217,
     "user_tz": -300,
     "elapsed": 330,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "be3fa1c5-f950-4f37-fbba-b389a25d3620"
   },
   "outputs": [],
   "source": "# Read image in grayscale\nimg = read_gray(\n    [\n        \"/content/drive/MyDrive/IP/dataset/cameraman.tif\",\n        \"dataset/cameraman.tif\",\n        \"../lab1/img.png\",\n        \"../lab1/img_1.png\",\n    ],\n    fallback_shape=(256, 256),\n    seed=2,\n)\n\nshow(img, \"Grayscale Image\", cmap=\"gray\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "9af4a699",
   "metadata": {
    "id": "9af4a699"
   },
   "source": [
    "## 1-Histogram of an image\n",
    "\n",
    "**cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])**\n",
    "\n",
    "**images** : it is the source image of type uint8 or float32. it should be given in square brackets, ie, \"[img]\".\n",
    "\n",
    "**channels** : it is also given in square brackets. It is the index of channel for which we calculate histogram. For example, if input is grayscale image, its value is [0]. For color image, you can pass [0], [1] or [2] to calculate histogram of blue, green or red channel respectively.\n",
    "\n",
    "**mask** : mask image. To find histogram of full image, it is given as \"None\". But if you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask.\n",
    "\n",
    "**histSize** : this represents our BIN count. Need to be given in square brackets. For full scale, we pass [256].\n",
    "\n",
    "**ranges** : this is our RANGE. Normally, it is [0,256].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0e494",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "afc0e494",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940377133,
     "user_tz": -300,
     "elapsed": 488,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "89fec994-12f9-4199-d097-6f680783517f"
   },
   "outputs": [],
   "source": "hist = cv2.calcHist(images=[img], channels=[0], mask=None, histSize=[256], ranges=[0, 256])\n\nplt.figure(figsize=(8, 4))\nplt.bar(range(256), hist.ravel())\nplt.title('Histogram of image')\nplt.xlabel('Gray scale values')\nplt.ylabel('Frequency')\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e2e11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "3a2e2e11",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940385533,
     "user_tz": -300,
     "elapsed": 184,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "4ab45e84-2f26-4d09-e7f8-394c460e0357"
   },
   "outputs": [],
   "source": "# Another method\nhist, bins = np.histogram(img.ravel(), 256, [0, 256])\nplt.figure(figsize=(8, 4))\nplt.plot(hist)\nplt.title('Histogram (numpy)')\nplt.xlabel('Gray scale values')\nplt.ylabel('Frequency')\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "0a3098bd",
   "metadata": {
    "id": "0a3098bd"
   },
   "source": [
    "Let's look at another example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74ed7c",
   "metadata": {
    "id": "cf74ed7c"
   },
   "outputs": [],
   "source": "# Let's read two other images\nhigh = read_color(\n    [\n        \"/content/drive/MyDrive/IP/dataset/hist_highkey.jpg\",\n        \"dataset/hist_highkey.jpg\",\n        \"../lab1/img_1.png\",\n    ],\n    fallback_shape=(300, 400),\n    seed=3,\n)\nlow = read_color(\n    [\n        \"/content/drive/MyDrive/IP/dataset/hist_lowkey.jpg\",\n        \"dataset/hist_lowkey.jpg\",\n        \"../lab1/img.png\",\n    ],\n    fallback_shape=(300, 400),\n    seed=4,\n)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd24717",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "fdd24717",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941001246,
     "user_tz": -300,
     "elapsed": 186,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "ce674859-9ebf-436a-dc97-1a6b8cd70a63"
   },
   "outputs": [],
   "source": "# show images\nplt.figure(figsize=(10, 4))\nplt.subplot(121)\nplt.imshow(cv2.cvtColor(high, cv2.COLOR_BGR2RGB))\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\nplt.subplot(122)\nplt.imshow(cv2.cvtColor(low, cv2.COLOR_BGR2RGB))\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae29f82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "aae29f82",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941005287,
     "user_tz": -300,
     "elapsed": 172,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "a4ae601f-7a60-4277-cdf6-56b351f87609"
   },
   "outputs": [],
   "source": [
    "# Calculate histogram of both images for the last channel.\n",
    "# Channels can differ from 0 to 2.\n",
    "hist_high = cv2.calcHist([high],[2],None,[256],[0,256])\n",
    "hist_low = cv2.calcHist([low],[2],None,[256],[0,256])\n",
    "\n",
    "# Plot histograms\n",
    "plt.subplot(121)\n",
    "plt.plot(hist_high)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(hist_low)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050e8a2",
   "metadata": {
    "id": "a050e8a2"
   },
   "source": [
    "## 2-Cumulative histogram of an image\n",
    "\n",
    "**Calculate cumulative distribution function (CDF) of an image**\n",
    "\n",
    "The cumulative histogram of an image is produced by calculating the cumulative sum of that image's histogram. There is no specific function in OpenCV to obtain the CDF of an image; thus we use the cumsum function in Numpy. You can find more about the function [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c62e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c39c62e5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941009615,
     "user_tz": -300,
     "elapsed": 438,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "38a31a07-5a5f-4f91-dba8-6acd78c4f645"
   },
   "outputs": [],
   "source": [
    "cdf_low = hist_low.cumsum()\n",
    "cdf_high = hist_high.cumsum()\n",
    "\n",
    "# plot cumulative histograms\n",
    "plt.subplot(221), plt.plot(cdf_high), plt. title('cdf of bright image')\n",
    "plt.subplot(222), plt.plot(hist_high, 'k'), plt. title('hist of bright image')\n",
    "\n",
    "plt.subplot(223), plt.plot(cdf_low), plt. title('cdf of dark image')\n",
    "plt.subplot(224), plt.plot(hist_low, 'k'), plt. title('hist of dark image')\n",
    "\n",
    "# adjust the placement of subplots\n",
    "plt.subplots_adjust(bottom=1, right=1.5, top=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07917768",
   "metadata": {
    "id": "07917768"
   },
   "source": [
    "## 3-Histogram manipulation\n",
    "\n",
    "In order to continue image manipulation, first of all, we change the RGB images to grayscale using `cv2.cvtColor()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d76b3",
   "metadata": {
    "id": "700d76b3"
   },
   "outputs": [],
   "source": [
    "low_gray = cv2.cvtColor(low, cv2.COLOR_BGR2GRAY)\n",
    "high_gray = cv2.cvtColor(high, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b7537",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "6e9b7537",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941014115,
     "user_tz": -300,
     "elapsed": 352,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "4d48d961-b217-4a66-b279-38c08c14715b"
   },
   "outputs": [],
   "source": [
    "# show images and their histograms\n",
    "plt.subplot(221), plt.imshow(high_gray, cmap='gray')\n",
    "plt.grid(False), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(223), plt.plot(cv2.calcHist([high_gray],[0],None,[256],[0,256]))\n",
    "\n",
    "plt.subplot(222), plt.imshow(low_gray, cmap='gray')\n",
    "plt.grid(False), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(224), plt.plot(cv2.calcHist([low_gray],[0],None,[256],[0,256]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002e923",
   "metadata": {
    "id": "b002e923"
   },
   "source": [
    "# Histogram Processing\n",
    "Histogram of an image can share valuable information with us.\n",
    "\n",
    "## Thresholding\n",
    "\n",
    "Thresholding is the simplest histogram processing application.\n",
    "\n",
    "np.histogram : Another way to calculate the image histogram is with **numpy** library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c681f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "2c8c681f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941030458,
     "user_tz": -300,
     "elapsed": 773,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "523db721-45c8-41f0-8011-57a87f4a1c75"
   },
   "outputs": [],
   "source": "img = read_gray(\n    [\n        \"/content/drive/MyDrive/IP/dataset/hist_lowkey.jpg\",\n        \"dataset/hist_lowkey.jpg\",\n        \"../lab1/img.png\",\n    ],\n    fallback_shape=(256, 256),\n    seed=5,\n)\nimg_hist = np.histogram(img, bins=256)\n\nplt.figure(figsize=(10, 4))\nplt.subplot(121)\nplt.imshow(img, cmap='gray')\nplt.axis('off')\nplt.subplot(122)\nplt.bar(img_hist[1][1:], img_hist[0])\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "b507b73f",
   "metadata": {
    "id": "b507b73f"
   },
   "source": [
    "### thresholded\n",
    "\n",
    "```python\n",
    "thresholded = img < t\n",
    "plt.imshow(thresholded)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54274d30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "id": "54274d30",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941034436,
     "user_tz": -300,
     "elapsed": 547,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "63677549-c21a-46e8-8847-6a1ba657009a"
   },
   "outputs": [],
   "source": [
    "t = 80\n",
    "thresholded = img < t\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.bar(img_hist[1][1:], img_hist[0])\n",
    "plt.vlines(t, 0, np.amax(img_hist[0]), colors='r', linewidth=5)\n",
    "plt.subplot(122)\n",
    "plt.imshow(thresholded, cmap=\"gray\")\n",
    "plt.subplots_adjust(right=3)\n",
    "plt.show()\n",
    "\n",
    "print(thresholded[150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954085d8",
   "metadata": {
    "id": "954085d8"
   },
   "source": [
    "### TASK 3 — Histogram equalization comparison\n",
    "\n",
    "1. Load a low-contrast grayscale image.\n",
    "2. Apply:\n",
    "   - `cv2.equalizeHist`\n",
    "   - CLAHE (`cv2.createCLAHE`)\n",
    "3. Plot histograms for original and both outputs.\n",
    "\n",
    "Use simple matplotlib plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d6246",
   "metadata": {
    "id": "e81d6246"
   },
   "outputs": [],
   "source": [
    "# TODO: load your image\n",
    "# img = cv2.imread(\"images/low_contrast.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Demo fallback\n",
    "img = np.uint8(np.clip(120 + 20*np.random.randn(256,256), 0, 255))\n",
    "\n",
    "eq = cv2.equalizeHist(img)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(img)\n",
    "\n",
    "def plot_hist(a, title):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.hist(a.ravel(), bins=256, range=(0,255))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Intensity\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "show(img, \"Original\", cmap=\"gray\")\n",
    "show(eq, \"Equalized\", cmap=\"gray\")\n",
    "show(clahe, \"CLAHE\", cmap=\"gray\")\n",
    "\n",
    "plot_hist(img, \"Histogram: Original\")\n",
    "plot_hist(eq, \"Histogram: Equalized\")\n",
    "plot_hist(clahe, \"Histogram: CLAHE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4fcc4",
   "metadata": {
    "id": "cfc4fcc4"
   },
   "source": [
    "---\n",
    "\n",
    "# 4) Image Enhancement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58da3f",
   "metadata": {
    "id": "0b58da3f"
   },
   "source": [
    "## Objectives\n",
    "- Apply basic enhancement operations (gamma, log, sharpening)\n",
    "- Compare the effect of parameters on visibility of detail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a161198",
   "metadata": {
    "id": "1a161198"
   },
   "source": [
    "## Image Enhancement (Contrast Enhancement)\n",
    "\n",
    "The process to enhance the visual quality of an image by manipulating its histogram (contrast) is called contrast enhancement. This process can be performed by using multiple linear or non-linear functions.\n",
    "\n",
    "![Contrast Enhancement](dataset/imgs/contrast.png)\n",
    "\n",
    "One of the methods to normalize and increase the quality and transparency of images in image processing is this method. if we stretch the histogram of the first image, we get a new normalized image. this will make the image clearer and brighter.\n",
    "The main concept of this method is to reduce the density of tangled pixels and stretch it and make the most gray intensity of the image occur and appear and reduce its darkness because in the original image we have the accumulation of close pixels.\n",
    "for calculate the new pixel in this method, we have this formula:\n",
    "\n",
    "**P_out=(P_in-c)((b-a)/(d-C))+a**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb01d73",
   "metadata": {
    "id": "afb01d73"
   },
   "source": [
    "#### For Image Enhancement in this section we describe two methods\n",
    "\n",
    "- Contrast stretching\n",
    "- Histogram Stretching\n",
    "\n",
    "![Contrast Enhancement](dataset/imgs/Image-Enhancement.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5252968",
   "metadata": {
    "id": "a5252968"
   },
   "source": [
    "### For Example : Contrast stretching\n",
    "\n",
    "![Contrast Enhancement](dataset/imgs/contrast-stretching-example.png)\n",
    "\n",
    "**P_out=(P_in-c)((b-a)/(d-C))+a**\n",
    "\n",
    "```text\n",
    "P_out ∶ new pixel (normalized)\n",
    "a,b∶ the range of numbers we want to normalize => (0, 255) 8-bit\n",
    "c: the smallest gray scale pixel in the first image => c=10\n",
    "d: the largest gray scale pixel in the first image => d=249\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b449173",
   "metadata": {
    "id": "3b449173"
   },
   "source": [
    "```\n",
    "P0 = (249-10) * ((255-0)/(249-10))+0 = 255   \n",
    "P1 = (108-10) * (1.06) = 103.88 ≈104\n",
    "P2 = (110-10) * (1.06) = 106\n",
    "P3 = (113-10) * (1.06) = 109.18 ≈ 109\n",
    "P4 = (10-10) * (1.06) = 0\n",
    "P5 = (98-10) * (1.06) = 93.28 ≈ 93\n",
    "P6 = (108-10) * (1.06) = 103.88 = 104\n",
    "P7 = (114-10) * (1.06) = 110.24 ≈ 110\n",
    "P8 = (85-10) * (1.06) = 79.5 ≈ 80\n",
    "P9 = (100-10) * (1.06) = 95.4 ≈ 95\n",
    "P10 = (96-10) * (1.06) = 91.16 ≈ 91\n",
    "P11 = (104-10) * (1.06) = 99.64 ≈ 100\t     \t  \n",
    "P12 = (85-10) * (1.06) = 79.5 ≈ 80\n",
    "P13 = (87-10) * (1.06) = 81.62 ≈ 82\n",
    "P14 = (95-10) * (1.06) = 90.10 ≈ 90\n",
    "P15 = (98-10) * (1.06) = 93.28 ≈ 93\n",
    "```\n",
    "\n",
    "### New Image after contrast stretching\n",
    "```text\n",
    "255\t104\t106\t109\n",
    "0\t93\t104\t110\n",
    "80\t95\t91\t100\n",
    "80\t82\t90\t93\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168915",
   "metadata": {
    "id": "65168915"
   },
   "source": [
    "### Histogram Stretching\n",
    "\n",
    "![Histogram stretching definition](http://s10.picofile.com/file/8396260626/transformation.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd5914",
   "metadata": {
    "id": "c8bd5914"
   },
   "source": [
    "## Example1: Contrast stretching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4341e9",
   "metadata": {
    "id": "db4341e9"
   },
   "source": [
    "P_out=(P_in-c)((b-a)/(d-C))+a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ced4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "317ced4a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941068348,
     "user_tz": -300,
     "elapsed": 2855,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "36783411-8838-4c01-e623-dac3ba65ed04"
   },
   "outputs": [],
   "source": "# Compute histogram of the image\nimage = read_gray(\n    [\n        \"/content/drive/MyDrive/IP/dataset/einstein low contrast.tif\",\n        \"dataset/einstein low contrast.tif\",\n        \"../lab1/img.png\",\n    ],\n    fallback_shape=(256, 256),\n    seed=6,\n).astype(np.float32)\n\nhist_img = np.histogram(image, bins=256)\n\n# Create the stretched image by normalizing it between 0 and 255\nden = np.amax(image) - np.amin(image)\nstretched_img = (255.0 / (den + 1e-8)) * (image - np.amin(image))\nhist_strch = np.histogram(stretched_img, bins=256)\n\n# Original and stretched image + histograms\nplt.figure(figsize=(16, 6))\nplt.subplot(221), plt.xticks([]), plt.yticks([])\nplt.imshow(image.astype(np.uint8), cmap='gray', vmin=0, vmax=255)\n\nplt.subplot(222), plt.xlim([0, 255])\nplt.bar(hist_img[1][1:], hist_img[0], color='red', width=1.5)\n\nplt.subplot(223), plt.xticks([]), plt.yticks([])\nplt.imshow(stretched_img.astype(np.uint8), cmap='gray', vmin=0, vmax=255)\n\nplt.subplot(224), plt.xlim([0, 255])\nplt.bar(hist_strch[1][1:], hist_strch[0], color='blue', width=1.5)\n\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "e18bd259",
   "metadata": {
    "id": "e18bd259"
   },
   "source": [
    "## Example2: Contrast stretching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f058e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "fa7f058e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771941095547,
     "user_tz": -300,
     "elapsed": 965,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "c72807a6-b470-48a3-c999-5c48a7dc4337"
   },
   "outputs": [],
   "source": "# Compute histogram of the image\nimage = read_gray(\n    [\n        \"/content/drive/MyDrive/IP/dataset/pout.jpg\",\n        \"dataset/pout.jpg\",\n        \"../lab1/img_1.png\",\n    ],\n    fallback_shape=(256, 256),\n    seed=7,\n).astype(np.float32)\n\nhist_img = np.histogram(image, bins=256)\n\n# Create the stretched image by normalizing it between 0 and 255\nstretched = 255.0 / (np.amax(image) - np.amin(image) + 1e-8) * (image - np.amin(image))\nhist_strch = np.histogram(stretched, bins=256)\n\nplt.figure(figsize=(16, 6))\nplt.subplot(221), plt.xticks([]), plt.yticks([])\nplt.imshow(image.astype(np.uint8), cmap='gray', vmin=0, vmax=255)\n\nplt.subplot(222), plt.xlim([0, 255])\nplt.bar(hist_img[1][1:], hist_img[0], color='red', width=1.5)\n\nplt.subplot(223), plt.xticks([]), plt.yticks([])\nplt.imshow(stretched.astype(np.uint8), cmap='gray', vmin=0, vmax=255)\n\nplt.subplot(224), plt.xlim([0, 255])\nplt.bar(hist_strch[1][1:], hist_strch[0], color='blue', width=1.5)\n\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "330241a7",
   "metadata": {
    "id": "330241a7"
   },
   "source": [
    "# Histogram Equalization\n",
    "Histogram equalization is a method to process images in order to adjust the contrast of an image by modifying the intensity distribution of the histogram. The objective of this technique is to give a linear trend to the cumulative probability function associated to the image.\n",
    "\n",
    "The processing of histogram equalization relies on the use of the cumulative probability function (cdf). The cdf is a cumulative sum of all the probabilities lying in its domain and defined by:\n",
    "\n",
    "![Histogram Equalization](dataset/imgs/histeq1.png)\n",
    "![Histogram Equalization](dataset/imgs/histeq.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c397213",
   "metadata": {
    "id": "8c397213"
   },
   "source": [
    "# For Example\n",
    "\n",
    "In both contrast stretching and histogram equalization, the objective is to spread the gray levels over the entire allowable gray level range. While stretching is a linear process and is reversible, equalization is a nonlinear process and is irreversible. Histogram equalization tries to redistribute about the same number of pixels for each gray level and it is automatic. Consider the 4 × 4 4-bit image shown in Table 2.4 (left). The gray levels are in the range 0–15.\n",
    "\n",
    "![Histogram Equalization](dataset/imgs/histeq3.png)\n",
    "\n",
    "Apply the Histogram Equalization on the above image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539c524",
   "metadata": {
    "id": "b539c524"
   },
   "source": [
    "![Histogram Equalization](dataset/imgs/histeq4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6eb01b",
   "metadata": {
    "id": "8f6eb01b"
   },
   "source": [
    "New Image (after histogram equalization)\n",
    "\n",
    "```\n",
    "9\t11\t3\t11\n",
    "8\t3\t5\t7\n",
    "15\t15\t4\t15\n",
    "15\t6\t9\t1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1061be",
   "metadata": {
    "id": "5b1061be"
   },
   "outputs": [],
   "source": "mri_img = read_gray(\n    [\n        '/content/drive/MyDrive/IP/dataset/MRI-spine1.tif',\n        'dataset/MRI-spine1.tif',\n        '../lab1/img.png',\n    ],\n    fallback_shape=(256, 256),\n    seed=8,\n)\ncameraman_img = read_gray(\n    [\n        '/content/drive/MyDrive/IP/dataset/cameraman.tif',\n        'dataset/cameraman.tif',\n        '../lab1/img_1.png',\n    ],\n    fallback_shape=(256, 256),\n    seed=9,\n)\npout_img = read_gray(\n    [\n        '/content/drive/MyDrive/IP/dataset/pout.jpg',\n        'dataset/pout.jpg',\n        '../lab1/img.png',\n    ],\n    fallback_shape=(256, 256),\n    seed=10,\n)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdb028",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "37bdb028",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940685494,
     "user_tz": -300,
     "elapsed": 1738,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "95c866fb-77ec-4c7d-9c3f-c62984a5d612"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(231), plt.imshow(mri_img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(234), plt.hist(mri_img.ravel(), bins=100)\n",
    "\n",
    "plt.subplot(232), plt.imshow(cameraman_img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(235), plt.hist(cameraman_img.ravel(), bins=100)\n",
    "\n",
    "plt.subplot(233), plt.imshow(pout_img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(236), plt.hist(pout_img.ravel(), bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3dc3d",
   "metadata": {
    "id": "1fd3dc3d"
   },
   "outputs": [],
   "source": [
    "def histogramEqualization(f, bins=100):\n",
    "    his, be = np.histogram(f, bins=bins)\n",
    "    his = his.astype(float)/sum(his)\n",
    "    return np.interp(f, be, np.hstack((np.zeros((1)), np.cumsum(his))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8330820",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "e8330820",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940692528,
     "user_tz": -300,
     "elapsed": 773,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "96c14f33-e7a7-48fb-fde2-8aac8a3583cc"
   },
   "outputs": [],
   "source": [
    "image = pout_img\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(221), plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "histo, range = np.histogram(image, bins=100)\n",
    "plt.subplot(222), plt.bar(range[:-1], histo)\n",
    "\n",
    "Eq = histogramEqualization(image)\n",
    "plt.subplot(223), plt.imshow(Eq, cmap='gray')\n",
    "histo, range = np.histogram(Eq, bins=100)\n",
    "plt.subplot(224), plt.bar(range[:-1], histo)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabcd4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "fdabcd4c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940695818,
     "user_tz": -300,
     "elapsed": 123,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "02bcf13c-50b3-4f8f-fbaa-8246031758f0"
   },
   "outputs": [],
   "source": [
    "image = pout_img\n",
    "histo, range = np.histogram(image, bins=100)\n",
    "cdf_1 = np.cumsum(histo)\n",
    "\n",
    "Eq = histogramEqualization(image)\n",
    "histo, range = np.histogram(Eq, bins=100)\n",
    "cdf_2 = np.cumsum(histo)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cdf_1, 'b')\n",
    "plt.plot(cdf_2, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242051d",
   "metadata": {
    "id": "1242051d"
   },
   "source": [
    "### skimage.exposure.equalize_hist()\n",
    "\n",
    "We can use this function to calculate Histogram Equalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc7a19",
   "metadata": {
    "id": "decc7a19"
   },
   "source": [
    "### TASK 4 — Gamma sweep (very easy)\n",
    "\n",
    "Create a function `apply_gamma(img, gamma)` and test it for **three** values:\n",
    "- gamma < 1 (brighten)\n",
    "- gamma = 1 (no change)\n",
    "- gamma > 1 (darken)\n",
    "\n",
    "Show the three outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49a8db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cc49a8db",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771940701734,
     "user_tz": -300,
     "elapsed": 726,
     "user": {
      "displayName": "Behnam Kiani",
      "userId": "01216284884362879860"
     }
    },
    "outputId": "d87a7516-a460-41be-a660-07d79449762c"
   },
   "outputs": [],
   "source": [
    "def apply_gamma(img, gamma):\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    out = np.power(img, gamma)\n",
    "    return np.uint8(np.clip(out*255.0, 0, 255))\n",
    "\n",
    "# TODO: load grayscale image\n",
    "# img = cv2.imread(\"images/sample.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Demo fallback\n",
    "img = np.uint8(np.clip(60 + 80*np.random.rand(256,256), 0, 255))\n",
    "\n",
    "g1 = apply_gamma(img, 0.6)\n",
    "g2 = apply_gamma(img, 1.0)\n",
    "g3 = apply_gamma(img, 1.8)\n",
    "\n",
    "show(img, \"Original\", cmap=\"gray\")\n",
    "show(g1, \"Gamma=0.6\", cmap=\"gray\")\n",
    "show(g2, \"Gamma=1.0\", cmap=\"gray\")\n",
    "show(g3, \"Gamma=1.8\", cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c861ff5",
   "metadata": {
    "id": "3c861ff5"
   },
   "source": [
    "---\n",
    "\n",
    "## Submission checklist\n",
    "- All TASK cells completed  \n",
    "- Figures/plots are clear  \n",
    "- Add 1–2 lines of reflection under each TASK (what changed? why?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and Displaying Images (2 × 5 Grid)\n",
    "\n",
    "## Objective\n",
    "In this task, we will:\n",
    "\n",
    "- Read images from a dataset folder\n",
    "- Display the first 10 images\n",
    "- Arrange them in **2 rows and 5 columns**\n",
    "- Use OpenCV (`cv2`) for reading\n",
    "- Use Matplotlib for visualization\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1 — Import Required Libraries\n",
    "\n",
    "We use:\n",
    "\n",
    "- `os` → to access dataset files  \n",
    "- `cv2` → to read images  \n",
    "- `matplotlib` → to display images  \n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 — Define Dataset Path\n",
    "\n",
    "Specify the folder containing the images:\n",
    "\n",
    "```python\n",
    "dataset_path = \"path_to_your_dataset_folder\""
   ],
   "metadata": {
    "id": "zyfrn49_CYAZ"
   },
   "id": "zyfrn49_CYAZ"
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Auto-pick a dataset folder (prefers local folders in this project)\ndataset_candidates = [\n    Path('dataset'),\n    Path('../lab1'),\n    Path('.'),\n]\n\nexts = {'.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'}\nimage_files = []\nchosen_dataset = None\n\nfor cand in dataset_candidates:\n    if cand.exists() and cand.is_dir():\n        files = [p for p in cand.iterdir() if p.is_file() and p.suffix.lower() in exts]\n        if files:\n            chosen_dataset = cand\n            image_files = files\n            break\n\nplt.figure(figsize=(12, 5))\n\nif image_files:\n    print(f\"Using dataset folder: {chosen_dataset.resolve()}\")\n    image_files = image_files[:10]\n\n    for i in range(10):\n        p = image_files[i % len(image_files)]\n        img = cv2.imread(str(p))\n        if img is None:\n            img = np.zeros((120, 160, 3), dtype=np.uint8)\n            title = f\"missing_{i+1}\"\n        else:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            title = p.name\n\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(title[:20])\nelse:\n    print('No dataset images found. Showing synthetic demo images instead.')\n    rng = np.random.default_rng(42)\n    for i in range(10):\n        img = rng.integers(0, 256, size=(120, 160, 3), dtype=np.uint8)\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(f'demo_{i+1}')\n\nplt.tight_layout()\nplt.show()\n",
   "metadata": {
    "id": "-DbnXXKhCYfx"
   },
   "id": "-DbnXXKhCYfx",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task: Randomly Display Images from Dataset (2 × 5 Grid)\n",
    "\n",
    "## Objective\n",
    "\n",
    "Write a Python program that:\n",
    "\n",
    "- Reads images from a dataset folder\n",
    "- Randomly selects **10 images**\n",
    "- Displays them in a **2 rows × 5 columns** layout\n",
    "- Hides axis ticks\n",
    "- Shows the image filename as the title\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Use the following libraries:\n",
    "   - `os`\n",
    "   - `random`\n",
    "   - `cv2`\n",
    "   - `matplotlib.pyplot`\n",
    "\n",
    "2. Randomly select 10 images from the dataset using:\n",
    "   ```python\n",
    "   random.sample()"
   ],
   "metadata": {
    "id": "d1Ro_5heCpp2"
   },
   "id": "d1Ro_5heCpp2"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fxp4d6aHCqOE"
   },
   "id": "fxp4d6aHCqOE",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}